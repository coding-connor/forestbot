{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook has been used for the initial development and testing of the basic components of the Retrieval Augmented Generation (RAG) system. It includes various developmental stages from prototyping initial concepts to refining the functionalities of the RAG components. The code and insights gained from this notebook were instrumental in building a more structured and deployable version of the RAG system, which is encapsulated in the Call_RAG.py script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install pypdf\n",
    "#! pip install langchain\n",
    "#! pip install \"langchain[docarray]\"\n",
    "#! pip install chromadb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import sys\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../..\")\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv())  # read local .env file\n",
    "\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = [\n",
    "    PyPDFLoader(\"../pdf/EdAP 2020_EN.pdf\"),\n",
    "    PyPDFLoader(\"../pdf/SOF book-web-rev3d-hires.pdf\"),\n",
    "]\n",
    "docs = []\n",
    "for loader in loaders:\n",
    "    docs.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "878"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contenu de la page \n",
      "440   |  Les forêts du bassin du Congo\n",
      "BibliographieRoca T, Letouzé E. 2016. La révolution des données est-elle en marche ? Implications pour la statistique \n",
      "publique et la démocratie. Afrique contemporaine. 258(2):95-111.\n",
      "Rosen GE, Smith KF. 2010. Summarizing the evidence on the international trade in illegal wildlife. \n",
      "EcoHealth. 7(1):24-32.\n",
      "RRI (Rights and Resources Initiative). 2017. Securing community land rights : Priorities and Opportunities to \n",
      "advance climate and sustainable development\n",
      "METADATA : {'source': '../pdf/SOF book-web-rev3d-hires.pdf', 'page': 466}\n"
     ]
    }
   ],
   "source": [
    "page = docs[870]\n",
    "print(f\"Contenu de la page \\n{page.page_content[0:500]}\")\n",
    "print(f\"METADATA : {page.metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2196\n",
      "878\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1500, chunk_overlap=50, separators=[\"\\n\\n\", \"\\n\", \"(?<=\\. )\", \" \", \"\"]\n",
    ")\n",
    "splits = text_splitter.split_documents(docs)\n",
    "print(len(splits))\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embed / Vector store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup Embedding and Vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = OpenAIEmbeddings()\n",
    "persist_directory = \"../vectorstore/chroma/\"\n",
    "\n",
    "\n",
    "# Delete the persist_directory if you want to force the generatation of another vector store\n",
    "#! rm -rf persist_directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate new Vectore Store if foler Chroma is empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the vector store already exists\n",
    "if os.path.exists(persist_directory):\n",
    "    # If the vector store exists, load it\n",
    "    vectordb = Chroma(persist_directory=persist_directory, embedding_function=embedding)\n",
    "else:\n",
    "    # If the vector store does not exist, generate it\n",
    "    # Assuming 'splits' is a list of documents already defined elsewhere in your notebook\n",
    "    vectordb = Chroma.from_documents(\n",
    "        documents=splits, embedding=embedding, persist_directory=persist_directory\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page': 158, 'source': '../pdf/EdAP 2020_EN.pdf'}\n",
      "{'page': 216, 'source': '../pdf/SOF book-web-rev3d-hires.pdf'}\n",
      "{'page': 387, 'source': '../pdf/EdAP 2020_EN.pdf'}\n"
     ]
    }
   ],
   "source": [
    "# print(vectordb._collection.count())\n",
    "question = \"What is OFAC stand for ?\"\n",
    "answer_docs = vectordb.similarity_search(question, k=3)\n",
    "len(answer_docs)\n",
    "answer_docs[0].page_content\n",
    "for d in answer_docs:\n",
    "    print(d.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MMR search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page': 158, 'source': '../pdf/EdAP 2020_EN.pdf'}\n",
      "{'page': 387, 'source': '../pdf/EdAP 2020_EN.pdf'}\n"
     ]
    }
   ],
   "source": [
    "answer_docs = vectordb.max_marginal_relevance_search(question, k=2, fetch_k=3)\n",
    "len(answer_docs)\n",
    "answer_docs[0].page_content\n",
    "for d in answer_docs:\n",
    "    print(d.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter on SOF (State of forest) only (doesn't work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"source\",\n",
    "        description=\"The lecture the chunk is from, should be one of EdAP 2020_EN.pdf or SOF book-web-rev3d-hires.pdf`\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"page\",\n",
    "        description=\"The page from the document\",\n",
    "        type=\"integer\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "document_content_description = \"Report of forest and protected area\"\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo-instruct\", temperature=0)\n",
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm, vectordb, document_content_description, metadata_field_info, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "question = \"what OFAC stand for, check answer in SOF document\"\n",
    "docs = retriever.get_relevant_documents(question)\n",
    "for d in docs:\n",
    "    print(d.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compression of retrieved data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guillaume/.local/lib/python3.10/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "/home/guillaume/.local/lib/python3.10/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "/home/guillaume/.local/lib/python3.10/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "/home/guillaume/.local/lib/python3.10/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "OFAC and COMIFAC\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "- COMIFAC\n",
      "- Central Africa\n",
      "- sustainable and coordinated management of forest ecosystems\n",
      "- orientation, harmonization and monitoring of forestry and environmental policies\n",
      "- emerged from the commitments made in March 1999 by the Heads of State of Central Africa in the “Yaoundé Declaration”\n",
      "- ten member countries of the subregion\n",
      "- common natural heritage\n",
      "- legal framework governed by the February 2005 treaty: “Treaty on the Conservation and Sustainable Management of Forest Ecosystems in Central Africa and to establish the Central African Forests Commission”\n",
      "- Convergence Plan defines the shared ten-year intervention strategies of Central African States and development partners in the field of conservation and sustainable management of forest and savanna ecosystems\n",
      "- second edition of this plan, covering the period 2015-2025\n",
      "- Web site: www.comifac.org\n",
      "- OFAC: Central Africa Forest Observatory\n",
      "- specialised unit of COMIFAC\n",
      "- coordinating the Forest Observatory\n",
      "- COMIFAC National Coordination committees\n",
      "- collaboration with all of the partners producing and disseminating information on the forests and ecosystems of Central Africa\n",
      "- responsible for coordinating the collection and editing of data, the analysis of results and the dissemination of information\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "OFAC: OFAC thus provides the subregion and its partners with essential tools for steering and sharing knowledge for better governance and sustainable management of forest ecosystems. The unit contributes to the organization and dissemination of information within the Congo Basin Forest Partnership (CBFP). It benefits from a support project financed by the European Union and the BIOPAMA program (IUCN and JRC).\n",
      "COMIFAC: OFAC-COMIFAC & IUCN\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 4:\n",
      "\n",
      "- L’OFAC effectue déjà un travail de compilation des informations pour alimenter le suivi de la mise en oeuvre du Plan de convergence de la COMIFAC.\n",
      "- Il serait utile de renforcer les capacités de cette Cellule pour qu’elle soit en mesure de traiter des données sur les ODD, en plus des données collectées par les pays pour renseigner les indicateurs du Plan de convergence de la COMIFAC qu’elle traite déjà actuellement.\n"
     ]
    }
   ],
   "source": [
    "# Guillaume comment :\n",
    "# In this section, we will use a Langchain compressor to reduce the amount of text retrieve.\n",
    "# By doing this, the summarized text produced is almost an answer\n",
    "\n",
    "\n",
    "def pretty_print_docs(docs):\n",
    "    print(\n",
    "        f\"\\n{'-' * 100}\\n\".join(\n",
    "            [f\"Document {i+1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "# Wrap our vectorstore\n",
    "llm = OpenAI(temperature=0, model=\"gpt-3.5-turbo-instruct\")\n",
    "\n",
    "compressor = LLMChainExtractor.from_llm(llm)\n",
    "\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor, base_retriever=vectordb.as_retriever()\n",
    ")\n",
    "\n",
    "question = \"what is the difference between OFAC and COMIFAC?\"\n",
    "compressed_docs = compression_retriever.get_relevant_documents(question)\n",
    "pretty_print_docs(compressed_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question answering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stuff technics : all document are sent to the LLM to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are creating a answer chain with Langchain. We make a specific prompt.\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "# Build prompt\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. Use three sentences maximum. Keep the answer as concise as possible. Always say \"thanks for asking!\" at the end of the answer. \n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)\n",
    "\n",
    "# Run chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"OFAC is a specialized unit of COMIFAC responsible for coordinating the Forest Observatory and disseminating information on Central Africa's forests and ecosystems. COMIFAC, on the other hand, is an organization responsible for harmonizing and monitoring forestry and environmental policies in Central Africa. Thanks for asking!\""
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What is the difference between OFAC and COMIFAC?\"\n",
    "result = qa_chain.invoke({\"query\": question})\n",
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map reduce : it combine all retrieved data before sending to the LLM to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"OFAC's main expertise is in collecting and managing environmental data in Central Africa to support the sustainable management of forest ecosystems. It contributes to reducing deforestation by providing essential tools for steering and sharing knowledge for better governance and sustainable management of forest ecosystems in the region. Thanks for asking!\""
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_chain_mr = RetrievalQA.from_chain_type(\n",
    "    llm, retriever=vectordb.as_retriever(), chain_type=\"map_reduce\"\n",
    ")\n",
    "question = (\n",
    "    \"What is the main expertise of OFAC ? How it contribute to reduce deforestation ?\"\n",
    ")\n",
    "result = qa_chain.invoke({\"query\": question})\n",
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refine : it improve the answer with each different document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"OFAC's main expertise is in collecting and managing environmental data in Central Africa to support the sustainable management of forest ecosystems. It contributes to reducing deforestation by providing essential tools for steering and sharing knowledge for better governance and sustainable management of forest ecosystems in the region. Thanks for asking!\""
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_chain_mr = RetrievalQA.from_chain_type(\n",
    "    llm, retriever=vectordb.as_retriever(), chain_type=\"refine\"\n",
    ")\n",
    "question = (\n",
    "    \"What is the main expertise of OFAC ? How it contribute to reduce deforestation ?\"\n",
    ")\n",
    "result = qa_chain.invoke({\"query\": question})\n",
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q/A with memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "retriever = vectordb.as_retriever()\n",
    "qa = ConversationalRetrievalChain.from_llm(llm, retriever=retriever, memory=memory)\n",
    "\n",
    "question = (\n",
    "    \"What is the main expertise of OFAC ? How it contribute to reduce deforestation ?\"\n",
    ")\n",
    "result = qa.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The main expertise of OFAC (Central Africa Forest Observatory) lies in ensuring the availability of information to support the sustainable management of forest ecosystems in Central Africa. OFAC contributes to reducing deforestation by collecting and managing environmental data at different scales, conducting annual campaigns to collect reference data in its member states, and collaborating with various partners to harmonize and disseminate information. Additionally, OFAC plays a crucial role in promoting knowledge transfer and skills between countries and actors, ultimately providing essential tools for steering and sharing knowledge for better governance and sustainable management of forest ecosystems in the region.'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OFAC and COMIFAC are both mentioned in the provided context, but the text does not explicitly outline the specific differences between the two entities. The text describes OFAC as playing a role in data storage, analysis, and transmission to support decision-making within the reach of managers, while COMIFAC is mentioned in the context of a Council of Ministers and holders of global issues. For more detailed differences between OFAC and COMIFAC, further information or sources specific to these organizations would be needed.'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Which difference with COMIFAC ?\"  # Check if it understand it's difference between OFAC and COMIFAC\n",
    "result = qa.invoke({\"question\": question})\n",
    "result[\"answer\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
